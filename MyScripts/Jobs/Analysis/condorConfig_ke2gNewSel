#script to run analyzer on reconstructed files

## "Constants" 
## dataListsLocation= /afs/cern.ch/na62/offline/lists/Data/Reco/2017 #obsolete
dataListsLocation= /afs/cern.ch/na62/offline/lists/Data/Reco #path to list of data (keep it like this)
mcListsLocation= /afs/cern.ch/na62/offline/lists/MC/2016/v0.11.0/Reco/v0.11.0 
analysisScript= /afs/cern.ch/work/r/romano/private/NewUserDir/analysis_condor.sh 
executableFile= /afs/cern.ch/work/r/romano/private/NewUserDir/bin-slc6/ke2gNewSelection #name of analyzer
#executableName= threetrackanalysis
executableName= ke2gNewSelection #name of executable (can be same of analyzer name)

## Parameters
##runs= ke4 # name of list containing reconstructed MC files on which to run executable
##runs= 6431 6670 6610
#runs= 6291.list
## BadBurstList (from metadata) for Sample 2016A, revision v1.0.0
##runs= 6278 6288 6291 6292 6300 6302 6303 6304 6305 6306 6307 6309 6318 6319 6320 6321 6330 6341 6342 6343 6346 6348 6349 6350 6351 6352 6353 6354 6355 6356 6362 6363 6364 6365 6366 6367 6368 6369 6370 6371 6403 6419 6420 6422 6431 6433 6434 6435 6436 6437 6467 6468 6473 6477 6478 6479 6480 6483 6487 6488 6490 6491 6493 6494 6495 6496 6497 6498 6501 6502 6503 6507 6509 6510 6511 6512 6513 6514 6516 6520 6523 6528 6561 6563 6567 6568 6574 6575 6579 6581 6582 6583 6584 6585 6586 6587 6589 6590 6596 6597 6599 6609 6610 6611 6612 6613 6614 6615 6619 6620 6622 6624 6625 6627 6629 6630 6632 6633 6634 6635 6636 6637 6638 6639 6641 6642 6643 6645 6646 6647 6648 6650 6651 6652 6653 6654 6656 6658 6659 6660 6661 6662 6663 6664 6666 6668 6670 6671 6672 6673 6674 6675 6676 6677 6678 6680 6681 6682 6683 6684 6685 6692 6693 6694 6724 6725 6726
##BadBurstList for Sample 2017B, revision v1.0.0
runs= 7876 7877 7878 7879 7880 7881 7883 7884 7885 7886 7887 7888 7897 7898 7899 7900 7901 7902 7903 7904 7905 7906 7908 7909 7910 7911 7921 7923 7924 7926 7927 7929 7930 7931 7939 7940 7941 7942 7943 7944 7945 7946 7948 7949 7950 7951 7952 7953 7954 7955 7956 7966 7967 7968 7970 7971 7972 7973 7977 7978 7982 7983 7984 7985 7987 7988 7989 7991 7992 7993 7998 7999 8001 8002 8003 8004 8005 8006 8007 8010 8011 8013 8014 8015 8016 8017 8018 8026 8027 8028 8029 8030 8031 8032 8033 8034 8036 8038 8039 8040 8041 8042 8043 8044 8045 8046 8047 8050 8051 8053 8054 8055 8056 8058 8059 8060 8061 8062 8063 8064 8065 8066 8067 8069 8073 8074 8075 8077 8078 8079 8080 8081 8082 8083 8084 8085 8086 8087 8088 8089 8090 8091 8092 8093 8094 8095 8096 8097 8098 8100 8101 8102 8103 8104 8105 8106 8107

#filter= HNLV
#filesPerJob= 40
#jobFlavour= workday
#numberOfCPUs= 2 # 1 CPU = 35 Gb. N files per job * file size <= N CPU. better to keep N CPU low and send many many jobs
#outputDir= /afs/cern.ch/work/r/romano/private/NewUserDir/outfiles
#analysisDir= /afs/cern.ch/work/r/romano/private/NewUserDir # dir with executable
#myListDir= /afs/cern.ch/work/r/romano/private/NewUserDir # dir of personal list of files (if you set the runs parameter to mylist.list)